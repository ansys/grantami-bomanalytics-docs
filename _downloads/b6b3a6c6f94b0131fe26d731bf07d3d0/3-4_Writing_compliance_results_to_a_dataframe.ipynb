{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a07a81",
   "metadata": {},
   "source": [
    "# Writing Compliance Results to a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f1a53",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537f0f0",
   "metadata": {},
   "source": [
    "The BoM Analytics package presents compliance results in a hierarchical data structure. Alternatively, you can\n",
    "represent the data in a tabular data structure, where each row contains a reference to the parent row.\n",
    "This example shows how compliance data could be translated from one format to another, making use\n",
    "of a ``pandas.DataFrame`` object to store the tabulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7f6e7",
   "metadata": {},
   "source": [
    "## Perform a Compliance Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed61398",
   "metadata": {},
   "source": [
    "The first step is to perform a compliance query on an assembly that will result in a deeply\n",
    "nested structure. The code here is presented without explanation. For more information, see the\n",
    "the [Part Compliance Query](../2_Compliance_Queries/2-3_Part_compliance.ipynb) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad8147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ansys.grantami.bomanalytics import Connection, indicators, queries\n",
    "\n",
    "server_url = \"http://my_grantami_server/mi_servicelayer\"\n",
    "cxn = Connection(server_url).with_credentials(\"user_name\", \"password\").connect()\n",
    "svhc = indicators.WatchListIndicator(\n",
    "    name=\"SVHC\",\n",
    "    legislation_names=[\"REACH - The Candidate List\"],\n",
    "    default_threshold_percentage=0.1,\n",
    ")\n",
    "part_query = (\n",
    "    queries.PartComplianceQuery()\n",
    "    .with_record_history_ids([565060])\n",
    "    .with_indicators([svhc])\n",
    ")\n",
    "part_result = cxn.run(part_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd863a44",
   "metadata": {},
   "source": [
    "The ``part_result`` object contains the compliance result for every subitem. This is ideal for understanding\n",
    "compliance at a certain 'level' of the structure, For example, we can display the compliance for each item directly\n",
    "under the root part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84530d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for part in part_result.compliance_by_part_and_indicator[0].parts:\n",
    "    print(\n",
    "        f\"Part ID: {part.record_history_identity}, \"\n",
    "        f\"Compliance: {part.indicators['SVHC'].flag}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443efa5b",
   "metadata": {},
   "source": [
    "However, this structure makes it difficult to compare items at different levels. To do that, we want to flatten the\n",
    "data into a tabular structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae4cee",
   "metadata": {},
   "source": [
    "## Flatten the Hierarchical Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598609c",
   "metadata": {},
   "source": [
    "We will flatten the data into a ``list`` of ``dict`` objects, where each ``dict`` represents an item in the\n",
    "hierarchy, and each value in the ``dict`` represents a property of that item. This structure can then\n",
    "be used either directly or used to construct a ``DataFrame``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3e6c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "First, define a helper function to transform a ``ComplianceQueryResult`` object into a ``dict``. In addition to\n",
    "storing properties that are intrinsic to the item (such as the ID, type, and SVHC result), we want to store\n",
    "structural information, such as the level of the item and the ID of its parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4965066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dict(item, item_type, level, parent_id):\n",
    "    \"\"\"Add a BoM item to a list\"\"\"\n",
    "    item_id = item.record_history_identity\n",
    "    indicator = item.indicators[\"SVHC\"]\n",
    "    row = {\n",
    "        \"Item\": item_id,\n",
    "        \"Parent\": parent_id,\n",
    "        \"Type\": item_type,\n",
    "        \"SVHC\": indicator,\n",
    "        \"Level\": level,\n",
    "    }\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32a50e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "To help with the flattening process, we will also define a schema, which describes which child item types each item\n",
    "type can contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277977f0",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"Part\": [\"Part\", \"Specification\", \"Material\", \"Substance\"],\n",
    "    \"Specification\": [\"Specification\", \"Coating\", \"Material\", \"Substance\"],\n",
    "    \"Material\": [\"Substance\"],\n",
    "    \"Coating\": [\"Substance\"],\n",
    "    \"Substance\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77874914",
   "metadata": {},
   "source": [
    "The function itself performs the flattening via a stack-based approach, where the children of the item currently\n",
    "being processed are iteratively added to the ``items_to_process`` stack. Since this stack is being both modified and\n",
    "iterated over, we must use a ``while`` loop and ``.pop()`` statement instead of a ``for`` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f7646",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The stack uses a special type of collection called a ``deque``, which is similar to a ``list`` but is optimized for\n",
    "these sorts of stack-type use cases involving repeated calls to ``.pop()`` and ``.extend()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd6a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def flatten_bom(root_part):\n",
    "    result = []  # List that will contain all dicts\n",
    "\n",
    "    # The stack contains a deque of tuples: (item_object, item_type, level, parent_id)\n",
    "    # First seed the stack with the root part\n",
    "    items_to_process = deque([(root_part, \"Part\", 0, None)])\n",
    "\n",
    "    while items_to_process:\n",
    "        # Get the next item from the stack\n",
    "        item_object, item_type, level, parent = items_to_process.pop()\n",
    "        # Create the dict\n",
    "        row = create_dict(item_object, item_type, level, parent)\n",
    "        # Append it to the result list\n",
    "        result.append(row)\n",
    "\n",
    "        # Compute the properties for the child items\n",
    "        item_id = item_object.record_history_identity\n",
    "        child_items = schema[item_type]\n",
    "        child_level = level + 1\n",
    "\n",
    "        # Add the child items to the stack\n",
    "        if \"Part\" in child_items:\n",
    "            items_to_process.extend([(p, \"Part\", child_level, item_id)\n",
    "                                     for p in item_object.parts])\n",
    "        if \"Specification\" in child_items:\n",
    "            items_to_process.extend([(s, \"Specification\", child_level, item_id)\n",
    "                                     for s in item_object.specifications])\n",
    "        if \"Material\" in child_items:\n",
    "            items_to_process.extend([(m, \"Material\", child_level, item_id)\n",
    "                                     for m in item_object.materials])\n",
    "        if \"Coating\" in child_items:\n",
    "            items_to_process.extend([(c, \"Coating\", child_level, item_id)\n",
    "                                     for c in item_object.coatings])\n",
    "        if \"Substance\" in child_items:\n",
    "            items_to_process.extend([(s, \"Substance\", child_level, item_id)\n",
    "                                     for s in item_object.substances])\n",
    "\n",
    "    # When the stack is empty, the while loop exists. Return the result list.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c86e47",
   "metadata": {},
   "source": [
    "Finally, call the function above against the results from the compliance query and use the list to create a\n",
    "``DataFrame``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302132b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = flatten_bom(part_result.compliance_by_part_and_indicator[0])\n",
    "df_full = pd.DataFrame(data)\n",
    "print(f\"{len(df_full)} rows\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365ed98",
   "metadata": {},
   "source": [
    "## Post-processing the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8070e",
   "metadata": {},
   "source": [
    "Now that we have the data in a ``DataFrame``, we can perform operations across all levels of the structure more\n",
    "easily. For example, we can delete all rows that are less than the 'Above Threshold' state, retaining only rows that\n",
    "are non-compliant. (Note that this reduces the number of rows significantly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe97d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = indicators.WatchListFlag.WatchListAboveThreshold\n",
    "df_non_compliant = df_full.drop(df_full[df_full.SVHC < threshold].index)\n",
    "print(f\"{len(df_non_compliant)} rows\")\n",
    "df_non_compliant.head()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
